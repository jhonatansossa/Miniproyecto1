{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"emotions_fuctions.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"lCOcPCMaSMgr"},"source":["import numpy as np\n","from scipy import signal\n","from scipy.interpolate import interp1d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nP5-lLJWegH6","executionInfo":{"status":"ok","timestamp":1604688882987,"user_tz":300,"elapsed":750,"user":{"displayName":"JHONATAN FELIPE SOSSA ROJO","photoUrl":"","userId":"01879645207948868805"}},"outputId":"cdf50f85-1add-4929-cd60-c5d1debe49a1","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bFJdyjLQbrun"},"source":["def butter_lowpass_filter(data, cutoff, fs, order):\n","    nyq = 0.5*fs\n","    normal_cutoff = cutoff / nyq\n","    # Get the filter coefficients \n","    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n","    y = signal.filtfilt(b, a, data)\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2w5qT65btXP"},"source":["def butter_passband_filter(data, lowcut, highcut, fs, order):\n","    nyq = 0.5*fs\n","    normal_lowcut = lowcut / nyq\n","    normal_highcut = highcut / nyq\n","    b, a = signal.butter(order, [normal_lowcut, normal_highcut], btype='band', analog=False)\n","    y = signal.filtfilt(b, a, data)\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3bY3DPkbvOf"},"source":["def logEnergy(sig,fs):\n","    logE=-1e30\n","    if len(sig)>0:\n","        sig2=np.power(sig,2)\n","        sumsig2 = np.sum(sig2)/len(sig2)\n","        logE=10*np.log10(sumsig2)\n","    return logE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RvMP3_babyCo"},"source":["def mu_ener_var(sig):\n","    feat_mu = np.mean(sig)\n","    feat = np.power(sig,2)\n","    feat_energy = np.sum(np.absolute(feat))\n","    feat_variance = np.var(sig)\n","    return np.hstack([feat_mu, feat_energy, feat_variance])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ft7X3KXBb0Jq"},"source":["def diffe(sig):\n","    sig = np.delete(sig, [14,15,18,23], axis=0)\n","    diferencias = []\n","    for i in range(int(len(sig)/2)):\n","        diferencias.append(sig[i]-sig[i+14])\n","    return np.vstack(diferencias)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FewjszOj5WN9"},"source":["def extract_features(sigs, fs):\n","    GSR_ = GSR(sigs[36], fs)\n","    BVP_ = BVP(sigs[38], fs)\n","    Respiration_ = Respiration(sigs[37],fs)\n","    Temperature_ = Temperature(sigs[39],fs)\n","    EMGEOG_ = EMGEOG(sigs[32],sigs[33],sigs[34],sigs[35],fs)\n","    EEG_ = EEG(sigs[0:32],fs)\n","    return np.hstack([GSR_, BVP_, Respiration_, Temperature_, EMGEOG_, EEG_])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7x1VII45Y08"},"source":["def EEG(feats,fs):\n","    dife = diffe(feats)\n","    order=2\n","    power = []\n","    \n","    feats = np.vstack([feats,dife])\n","    \n","    for i in range(feats.shape[0]):\n","        sig = feats[i]\n","        for x in range(4):\n","            if x == 0:\n","                lowcut = 3.5\n","                highcut = 7.5\n","            if x == 1:\n","                lowcut = 8\n","                highcut = 13\n","            if x == 2:\n","                lowcut = 12\n","                highcut = 30\n","            if x == 3:\n","                lowcut = 25\n","                highcut = 60\n","            \n","            sig_filt = butter_passband_filter(sig, lowcut, highcut, fs, order)\n","            #f, Pxx = signal.welch(sig_filt, fs, nperseg=64, window=np.ones(64))\n","            #AbsPxx = np.sum(Pxx)\n","            \n","            size_frameS=0.02*float(fs)\n","            size_stepS=0.01*float(fs)\n","            overlap=size_stepS/size_frameS\n","            nF=int((len(sig_filt)/size_frameS/overlap))-1\n","            \n","            power_first = []\n","            for l in range(nF):\n","                feat_frame = sig_filt[int(l*size_stepS):int(l*size_stepS+size_frameS)]\n","                power_f = logEnergy(feat_frame,fs)\n","                power_f = np.power(10,(power_f/10))\n","                power_first.append(power_f)\n","                \n","            power.append(np.mean(power_first))\n","            #LogPxx = 20*np.log(AbsPxx)\n","            \n","    \n","    #alpha 8-13Hz\n","    #beta 12-30Hz\n","    #theta 3.5-7.5Hz\n","    #gamma 25-100Hz\n","    \n","    \n","    return np.hstack(power)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C0zbJhUR5hxU"},"source":["def EMGEOG(feat1, feat2, feat3, feat4, fs):\n","    \n","    feat_one = mu_ener_var(feat1)\n","    feat_two = mu_ener_var(feat2)\n","    feat_three = mu_ener_var(feat3)\n","    feat_four = mu_ener_var(feat4)\n","    \n","    return np.hstack([feat_one, feat_two, feat_three, feat_four])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sa_3BYt85ltM"},"source":["def Temperature(feat,fs):\n","    \n","    feat_mu = np.mean(feat)\n","    feat_diff = np.mean(np.diff(feat))\n","    \n","    order=2\n","        \n","    cutoff = 0.1\n","    lowcut = 0.1\n","    highcut = 0.2\n","    \n","    size_frameS=0.02*float(fs)\n","    size_stepS=0.01*float(fs)\n","    overlap=size_stepS/size_frameS\n","    nF=int((len(feat)/size_frameS/overlap))-1\n","    power_first = []\n","    power_second = []\n","    \n","    first_feat = butter_lowpass_filter(feat, cutoff, fs, order)\n","    second_feat = butter_passband_filter(feat, lowcut, highcut, fs, order)\n","    \n","    for l in range(nF):\n","        feat_frame = first_feat[int(l*size_stepS):int(l*size_stepS+size_frameS)]\n","        power_f = logEnergy(feat_frame,fs)\n","        power_f = np.power(10,power_f/10)\n","        power_first.append(power_f)\n","        \n","        feat_frame = second_feat[int(l*size_stepS):int(l*size_stepS+size_frameS)]\n","        power_s = logEnergy(feat_frame,fs)\n","        power_s = np.power(10,power_s/10)\n","        power_second.append(power_s)\n","        \n","        \n","    power_first_mu = np.mean(power_first)\n","    power_second_mu = np.mean(power_second)\n","    \n","    return np.hstack([feat_mu, feat_diff, power_first_mu, power_second_mu])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ac0bq3V5sJG"},"source":["def Respiration(feat,fs):\n","    \n","    order=2\n","        \n","    #first passband filter\n","    lowcut = 0.05\n","    highcut = 0.25\n","        \n","    first_feat = butter_passband_filter(feat, lowcut, highcut, fs, order)\n","        \n","    #second passband filter\n","    lowcut = 0.25\n","    highcut = 0.5\n","        \n","    second_feat = butter_passband_filter(feat, lowcut, highcut, fs, order)\n","    \n","    energy_feat_first = logEnergy(first_feat,fs)\n","    energy_feat_second = logEnergy(second_feat,fs)\n","    \n","    energy_rate = energy_feat_first-energy_feat_second\n","    \n","    feat_mu = np.mean(feat)\n","    \n","    feat_diff_mu = np.mean(np.diff(feat))\n","    \n","    feat_max = np.max(feat)\n","    \n","    return np.hstack([energy_rate, feat_mu, feat_diff_mu, feat_max])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ORbeanth5yjc"},"source":["def BVP(feat, fs):\n","    \n","    size_frameS=10*float(fs)\n","    size_stepS=5*float(fs)\n","    overlap=size_stepS/size_frameS\n","    nF=int((len(feat)/size_frameS/overlap))-1\n","\n","    hrs=[]\n","    hrvs=[]\n","    rrs_f=[]\n","\n","    for l in range(nF):\n","        feat_frame = feat[int(l*size_stepS):int(l*size_stepS+size_frameS)]\n","        \n","        feat_frame = 10*np.diff(feat_frame,1)\n","        \n","        peaks, _ = signal.find_peaks(feat_frame, prominence = 0.03)\n","        peaks_copy = peaks\n","        \n","        feat_copy = feat_frame[peaks]\n","        \n","        peaks1, _ = signal.find_peaks(np.concatenate(([0],feat_frame[peaks],[0])), prominence = 0.03)\n","        \n","        feat_copy1 = feat_copy[peaks1-1]\n","        \n","        peaks2 = []\n","        for i in range(len(feat_copy1)):\n","            idx= np.where(feat_copy1[i]==feat_copy)[0][0]\n","            peaks2.append(peaks_copy[idx])\n","            \n","            feat_copy = np.delete(feat_copy, idx)\n","            peaks_copy = np.delete(peaks_copy, idx)\n","            \n","        peaks2= np.hstack(peaks2)\n","        \n","       \n","        \n","        rrs = []\n","        rmssd = []\n","        cont = 0\n","        for i in range(len(peaks2)-2):\n","            one = peaks2[i]\n","            two = peaks2[i+1]\n","            interval = (two - one)/fs\n","            rrs.append(interval)\n","        rrs_copy = rrs.copy()\n","        rrs.reverse()\n","        rmssd = np.diff(rrs)\n","        rmssd = np.power(rmssd,2)\n","        rmssd = rmssd[::-1]\n","        \n","            # cont = cont + 1\n","            # if i != 0:\n","            #     pw = np.power((rrs[i-1]-rrs[i]),2)\n","            #     rmssd.append(pw)\n","            #     cont = 1\n","        \n","        rmssd = np.power(np.sum(rmssd),1/2)\n","        hr = len(peaks2)/(size_frameS/fs)\n","        \n","        hrs.append(hr)\n","        hrvs.append(rmssd)\n","        rrs_f.append(rrs_copy)\n","        \n","   \n","    hrs = static_feats(hrs)\n","    hrvs = static_feats(hrvs)\n","    rrs_f = static_feats(np.hstack(rrs_f))    \n","\n","    \n","    return np.hstack([hrs, hrvs, rrs_f])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lk-onFfv56n8"},"source":["def GSR(feat, fs):\n","    \n","    dfeat = np.diff(feat, 1, axis=0)\n","    \n","    #Average skin resistance, average of derivative, average of derivative for negative values only\n","    feat_mu = np.mean(feat,0)\n","    dfeat_mu = np.mean(dfeat,0)\n","    ndfeat_mu = np.mean(np.where(dfeat < 0)[0],0)\n","    \n","    #Filter parameters\n","    cutoff = 2.4\n","    order=2\n","    \n","    #filter\n","    feat = butter_lowpass_filter(feat, cutoff, fs, order)\n","    \n","    #spectral power\n","    fourier_transform = np.fft.rfft(feat)\n","    abs_fourier_transform = np.abs(fourier_transform)\n","    power_spectrum = np.square(abs_fourier_transform)\n","    frequency = np.linspace(0, 128/2, len(power_spectrum))\n","    #    plt.plot(frequency, abs_fourier_transform)\n","    \n","    #select the first ten spectral power\n","    peaks, _ = signal.find_peaks(power_spectrum, height=0)\n","    \n","\n","    \n","    return np.hstack([feat_mu, dfeat_mu, ndfeat_mu])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcYKZ5jQ6Btr"},"source":["def static_feats(featmat):\n","    \"\"\"Compute static features\n","    :param featmat: Feature matrix\n","    :returns: statmat: Static feature matrix\n","    \"\"\"\n","    mu = np.mean(featmat,0)\n","    st = np.std(featmat,0)\n","    statmat = np.hstack([mu,st])    \n","    return statmat"],"execution_count":null,"outputs":[]}]}